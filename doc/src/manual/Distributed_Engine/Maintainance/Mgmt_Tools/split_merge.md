[^_^]:
    容灾切换合并工具
    作者：赵育
    时间：20190507
    评审意见
    王涛：
    许建辉：
    市场部：

用户可以通过安装路径 `tools/dr_ha` 下的脚本实现 SequoiaDB 巨杉数据库集群环境的分离及合并、故障节点的剔除与加入功能。

集群分离与合并工具
----

集群分离与合并工具适用于需要 SequoiaDB 提供可靠的备份方案及高可用方案，以应对可能发生的各种意外，确保用户的数据在各种意外情况下都能得到有效保障。典型的应用场景可参考[高可用与容灾][HA_DR]章节。

### 使用说明

集群分离与合并工具包括如下几个脚本：

- init.sh：初始化脚本，SequoiaDB 集群环境正常时初始化集群信息，用于保存当前集群所有的组信息，供集群合并时恢复集群环境

- split.sh：集群分离脚本，当两个子网发生网络分离，相互无法访问时，使用该脚本进行集群分离，让两个子网分离成两个独立的集群

- merge.sh：集群合并脚本，当两个子网网络连通时，使用该脚本将之前分离的两个独立集群合并成一个大集群

- cluster_opr.js：参数定义、初始化、集群分离、集群合并的功能实现

进行集群的分离与合并必须满足如下条件：

- 整个 SequoiaDB 集群环境必须分布在两台及以上的机器上，并且能够将这些机器划分成两个子网

- 编目复制组的节点必须在两个子网下的机器上都进行部署

- 协调节点必须在两个子网下的机器上都进行部署

- 同一个数据复制组中的节点必须在两个子网下的机器上都进行部署

### 操作步骤

1. 将整个 SequoiaDB 集群按照前期规划划分成两个子网 Sub1、Sub2：

   - Sub1：位于主机房，该子网下有两台主机，为：Sub1-Host1、Sub1-Host2

   - Sub2：位于备机房，该子网下有一台机器，为：Sub2-Host1

     机器上部署的 SequoiaDB 集群如下：

     | 机器名     | 协调节点 | 编目节点 | 数据节点（group1、group2、group3） | 安装目录       |
     | ---------- | -------- | -------- | ---------------------------------- | -------------- |
     | Sub1-Host1 | Y        | Y        | 每个数据组均部署一个节点           | /opt/sequoiadb |
     | Sub1-Host2 | Y        | Y        | 每个数据组均部署一个节点           | /opt/sequoiadb |
     | Sub2-Host1 | Y        | Y        | 每个数据组均部署一个节点           | /opt/sequoiadb |

2. 在两个子网中各选一台机器，作为容灾切换合并的执行机，例如 Sub1-Host1 和 Sub2-Host1。

3. 根据实际情况修改机器 Sub1-Host1 和 Sub2-Host1 上 `init.sh` , `split.sh` , `merge.sh` 中 SEQPATH 变量，例如修改为 `/opt/sequoiadb`。

4. 根据实际配置修改机器 Sub1-Host1 和 Sub2-Host1 上 `cluster_opr.js` 的参数定义部分，主要参数说明如下：

| 参数名 | 描述  |
| ------------ | ------------- |
| USERNAME| 登录所有机器的用户名（所有机器用户名及密码需要统一）|
| PASSWD | 登录所有机器用户名对应的密码 |
| SDBUSERNAME | 登录 SequoiaDB 集群环境的用户名（如果数据库没有开启用户鉴权，则可以不填）|
| SDBPASSWD | 登录 SequoiaDB 集群环境用户名对应的密码（如果数据库没有开启用户鉴权，则可以不填）|
| SUB1HOSTS | 子网 1 的服务器列表 |
| SUB2HOSTS | 子网 2 的服务器列表 |
| COORDADDR | 协调节点地址，如果协调节点已经在协调节点组信息中，则此处填写一个可用地址即可 |
| CURSUB | 当前脚本所处的是子网 1 还是子网 2（注意：该参数非常重要） |
| ACTIVE | 当前子网是否为激活状态，如果取 false，则在集群执行切换后，当前子网的集群为只读状态 |
| NEEDREELECT | 执行初始化脚本时是否重新选主，为了让主节点在主数据中心的几个主机上，需要设置为 true |
| NEEDBROADCASTINITINFO | 是否将初始化脚本生成的集群信息文件分发到集群的所有主机上，如果设置为 false，分别在子网 1 及子网 2 中的机器 Sub1-Host1 和 Sub2-Host1 上执行初始化脚本 |

5. 分别在子网 1 和子网 2 的机器 Sub1-Host1 和 Sub2-Host1 上执行 `init.sh`，进行初始化。

6. 当子网 1 和子网 2 出现了网络分离，相互无法访问时，在子网 1 和子网 2 的机器 Sub1-Host1 和 Sub2-Host1 上执行 split.sh 进行集群分离，让子网 1 和子网 2 分离成独立的集群，此时 ACTIVE 配置为 true 的子网可以对外提供读写服务，ACTIVE 配置为 false 的子网只提供读操作。

7. 当子网 1 和子网 2 网络连通后，在子网 1 和子网 2 的机器 Sub1-Host1 和 Sub2-Host1 上执行 `merge.sh` 进行集群合并，将子网 1 和子网 2 分别独立的两个集群重新合并成为一个大集群。

故障节点的剔除与加入工具
----

故障节点的剔除与加入工具适用于当 SequoiaDB 集群环境中的部分节点发生故障导致复制组不可用（无主）时，通过该工具可剔除不可用的节点，待故障节点恢复后，该工具也可将该节点重新加入。

### 使用说明

故障节点的剔除与加入工具包括如下几个脚本：

- init.sh：初始化脚本，SequoiaDB 集群环境正常时初始化集群信息，用于保存当前集群所有的组信息，供节点恢复后重新加入到对应复制组中

- detachGroupNode.sh：剔除故障节点脚本，当复制组内节点发生故障时，使用该脚本将故障节点剔除

- attachGroupNode.sh：节点恢复后，加入节点脚本，当复制组内故障节点恢复后，使用该脚本将恢复后的节点重新加入复制组

### 操作步骤

1. 将整个 SequoiaDB 集群按照前期规划选定一台机器作为故障节点剔除和加入的执行机，例如：host1。

2. 根据 SequoiaDB 集群环境的实际安装路径修改机器 host1 上 `init.sh`, `detachGroupNode.sh`, `attachGroupNode.sh` 中 SEQPATH 变量，例如实际安装路径为 `/opt/sequoiadb`，则该变量赋值为 `/opt/sequoiadb`。

3. 根据实际配置修改机器host1 上 `cluster_opr.js` 的参数定义部分，主要参数说明如下：

   | 参数名 | 描述  |
   | ------------ | ------------- |
   | USERNAME | 登录所有机器的用户名（所有机器用户名及密码需要统一）|
   | PASSWD | 登录所有机器用户名对应的密码 |
   | SDBUSERNAME | 登录 SequoiaDB 集群环境的用户名（如果数据库没有开启用户鉴权，则可以不填）|
   | SDBPASSWD | 登录 SequoiaDB 集群环境用户名对应的密码（如果数据库没有开启用户鉴权，则可以不填）|
   | SUB1HOSTS | 填本机机器名即可 |
   | COORDADDR | 协调节点地址，如果协调节点已经在协调节点组信息中，则此处填写一个可用地址即可 |
   | MINREPLICANUM | 剔除故障组节点后剩余的最小副本数，若剔除后剩余副本数小于最小福很数，将不会执行剔除操作 |
   | NEEDREELECT | 执行初始化脚本时是否重新选主，一般情况下不需重新选主，可设置为 false |
   |NEEDBROADCASTINITINFO | 是否将初始化脚本生成的集群信息文件分发到集群的所有主机上，一般设置为true，无需到每台机器上重复执行初始化脚本 |

4. 在 SequoiaDB 集群环境正常的情况下，在机器 host1 上执行 `init.sh`，此时会根据 NEEDBROADCASTINITINFO 参数的配置在本地（设置成 false ）或者集群中所有机器（设置为 true ）上生成的 `datacenter_init.info` 文件，该文件中保存了当前集群信息，默认生成在集群的安装目录下。

5. 当 SequoiaDB 集群中的部分节点发生故障导致复制组不可用（无主）时，选择一台存在 datacenter_init.info 文件的机器（如果与执行 `init.sh` 脚本的机器不同，那么同样也需要按照步骤 2 及步骤 3 对脚本中的参数进行配置），执行 `detachGroupNode.sh` 脚本，剔除不可用节点。

6. 当故障节点恢复后，选择一台存在 `datacenter_init.info` 文件的机器（如果与执行 `init.sh` 脚本的机器不同，那么同样也需要按照步骤 2 及步骤 3 对脚本中的参数进行配置），执行 `attachGroupNode.sh` 脚本，将恢复后的节点重新加入到对应复制组中。

[^_^]:
    本文使用到的所有链接及引用。
[HA_DR]:manual/Distributed_Engine/Maintainance/HA_DR/disaster_recovery.md
